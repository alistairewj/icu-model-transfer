{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import getpass\n",
    "\n",
    "# for configuring connection \n",
    "from configobj import ConfigObj\n",
    "import os\n",
    "\n",
    "# local utils\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: eicu\n",
      "Username: alistairewj\n"
     ]
    }
   ],
   "source": [
    "# Create a database connection using settings from config file\n",
    "config='db/config.ini'\n",
    "\n",
    "# connection info\n",
    "conn_info = dict()\n",
    "if os.path.isfile(config):\n",
    "    config = ConfigObj(config)\n",
    "    conn_info[\"sqluser\"] = config['username']\n",
    "    conn_info[\"sqlpass\"] = config['password']\n",
    "    conn_info[\"sqlhost\"] = config['host']\n",
    "    conn_info[\"sqlport\"] = config['port']\n",
    "    conn_info[\"dbname\"] = config['dbname']\n",
    "    conn_info[\"schema_name\"] = config['schema_name']\n",
    "else:\n",
    "    conn_info[\"sqluser\"] = 'postgres'\n",
    "    conn_info[\"sqlpass\"] = ''\n",
    "    conn_info[\"sqlhost\"] = 'localhost'\n",
    "    conn_info[\"sqlport\"] = 5432\n",
    "    conn_info[\"dbname\"] = 'eicu'\n",
    "    conn_info[\"schema_name\"] = 'public,eicu_crd'\n",
    "    \n",
    "# Connect to the eICU database\n",
    "print('Database: {}'.format(conn_info['dbname']))\n",
    "print('Username: {}'.format(conn_info[\"sqluser\"]))\n",
    "if conn_info[\"sqlpass\"] == '':\n",
    "    # try connecting without password, i.e. peer or OS authentication\n",
    "    try:\n",
    "        if (conn_info[\"sqlhost\"] == 'localhost') & (conn_info[\"sqlport\"]=='5432'):\n",
    "            con_eicu = psycopg2.connect(dbname=conn_info[\"dbname\"],\n",
    "                                   user=conn_info[\"sqluser\"])            \n",
    "        else:\n",
    "            con_eicu = psycopg2.connect(dbname=conn_info[\"dbname\"],\n",
    "                                   host=conn_info[\"sqlhost\"],\n",
    "                                   port=conn_info[\"sqlport\"],\n",
    "                                   user=conn_info[\"sqluser\"])\n",
    "    except:\n",
    "        conn_info[\"sqlpass\"] = getpass.getpass('Password: ')\n",
    "\n",
    "        con_eicu = psycopg2.connect(dbname=conn_info[\"dbname\"],\n",
    "                               host=conn_info[\"sqlhost\"],\n",
    "                               port=conn_info[\"sqlport\"],\n",
    "                               user=conn_info[\"sqluser\"],\n",
    "                               password=conn_info[\"sqlpass\"])\n",
    "eicu_schema = 'set search_path to ' + conn_info['schema_name'] + ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: mimic\n",
      "Username: alistairewj\n"
     ]
    }
   ],
   "source": [
    "# Create a database connection using settings from config file\n",
    "config='db/config-mimic.ini'\n",
    "\n",
    "# connection info\n",
    "conn_info = dict()\n",
    "if os.path.isfile(config):\n",
    "    config = ConfigObj(config)\n",
    "    conn_info[\"sqluser\"] = config['username']\n",
    "    conn_info[\"sqlpass\"] = config['password']\n",
    "    conn_info[\"sqlhost\"] = config['host']\n",
    "    conn_info[\"sqlport\"] = config['port']\n",
    "    conn_info[\"dbname\"] = config['dbname']\n",
    "    conn_info[\"schema_name\"] = config['schema_name']\n",
    "else:\n",
    "    conn_info[\"sqluser\"] = 'postgres'\n",
    "    conn_info[\"sqlpass\"] = ''\n",
    "    conn_info[\"sqlhost\"] = 'localhost'\n",
    "    conn_info[\"sqlport\"] = 5432\n",
    "    conn_info[\"dbname\"] = 'eicu'\n",
    "    conn_info[\"schema_name\"] = 'public,eicu_crd'\n",
    "    \n",
    "# Connect to the eICU database\n",
    "print('Database: {}'.format(conn_info['dbname']))\n",
    "print('Username: {}'.format(conn_info[\"sqluser\"]))\n",
    "if conn_info[\"sqlpass\"] == '':\n",
    "    # try connecting without password, i.e. peer or OS authentication\n",
    "    try:\n",
    "        if (conn_info[\"sqlhost\"] == 'localhost') & (conn_info[\"sqlport\"]=='5432'):\n",
    "            con_mimic = psycopg2.connect(dbname=conn_info[\"dbname\"],\n",
    "                                   user=conn_info[\"sqluser\"])            \n",
    "        else:\n",
    "            con_mimic = psycopg2.connect(dbname=conn_info[\"dbname\"],\n",
    "                                   host=conn_info[\"sqlhost\"],\n",
    "                                   port=conn_info[\"sqlport\"],\n",
    "                                   user=conn_info[\"sqluser\"])\n",
    "    except:\n",
    "        conn_info[\"sqlpass\"] = getpass.getpass('Password: ')\n",
    "\n",
    "        con_mimic = psycopg2.connect(dbname=conn_info[\"dbname\"],\n",
    "                               host=conn_info[\"sqlhost\"],\n",
    "                               port=conn_info[\"sqlport\"],\n",
    "                               user=conn_info[\"sqluser\"],\n",
    "                               password=conn_info[\"sqlpass\"])\n",
    "mimic_schema = 'set search_path to ' + conn_info['schema_name'] + ';'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same as above - but 24 hour matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== eICU ===\n",
      "   181 removed due to exclusion_non_adult\n",
      " 16311 removed due to exclusion_bad_data\n",
      "     0 removed due to exclusion_organ_donor\n",
      "101010 removed due to exclusion_by_apache\n",
      "\n",
      "107100 (53.32%) removed so far.\n",
      "  extra  23626 removed due to window time.\n",
      "\n",
      " 70133 (34.92%) - final cohort size.\n",
      "Exported 70133 rows to file.\n"
     ]
    }
   ],
   "source": [
    "print('=== eICU ===')\n",
    "query = eicu_schema + \"\"\"\n",
    "select co.*, tm.windowtime_hours\n",
    "from tr_cohort co\n",
    "left join tr_time_day1 tm\n",
    "on co.patientunitstayid = tm.patientunitstayid\n",
    "\"\"\"\n",
    "co_eicu = pd.read_sql_query(query, con_eicu)\n",
    "co_eicu.set_index('patientunitstayid', inplace=True)\n",
    "\n",
    "co_eicu = utils.drop_patients(co_eicu)\n",
    "\n",
    "query = eicu_schema + \"\"\"\n",
    "select co.patientunitstayid\n",
    "  , aiva.acutephysiologyscore as apsiii\n",
    "from tr_cohort co\n",
    "left join (select patientunitstayid, acutephysiologyscore from APACHEPATIENTRESULT where apacheversion = 'IVa') aiva\n",
    "on co.patientunitstayid = aiva.patientunitstayid\n",
    "order by 1, 2\n",
    "\"\"\"\n",
    "df_eicu = pd.read_sql_query(query, con_eicu)\n",
    "df_eicu.set_index('patientunitstayid', inplace=True)\n",
    "\n",
    "# static data\n",
    "query = eicu_schema + \"\"\"select * from tr_static_data\"\"\"\n",
    "df_eicu_static = pd.read_sql_query(query, con_eicu)\n",
    "df_eicu_static.set_index('patientunitstayid', inplace=True)\n",
    "\n",
    "# add in outcomes/static vars to the design matrix\n",
    "vars_static = ['death', 'ventdays',\n",
    "               'is_female', 'age',\n",
    "               'race_black', 'race_hispanic', 'race_asian', 'race_other',\n",
    "               'electivesurgery']\n",
    "X_eicu = df_eicu.merge(df_eicu_static[vars_static], how='inner',\n",
    "                       left_index=True, right_index=True)\n",
    "\n",
    "# add in hospitalid/outcomes to start of dataframe\n",
    "vars_outcome = ['hospitalid', 'hosp_los']\n",
    "X_eicu = co_eicu[vars_outcome].merge(X_eicu, how='inner',\n",
    "              left_index=True, right_index=True)\n",
    "\n",
    "# rearrange certain columns to beginning of dataframe\n",
    "# this is only for aesthetics - nice to have non-inputs at start of df\n",
    "vars_outcome = ['hospitalid', 'death', 'hosp_los', 'ventdays']\n",
    "X_eicu = X_eicu[ vars_outcome + [c for c in X_eicu.columns if c not in vars_outcome] ]\n",
    "X_eicu.head()\n",
    "\n",
    "# write to file\n",
    "X_eicu.to_csv('X_eicu_apsiii.csv.gz', compression='gzip')\n",
    "print('Exported {} rows to file.'.format(X_eicu.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MIMIC ===\n",
      "  8109 removed due to exclusion_non_adult\n",
      "  1347 removed due to exclusion_bad_data\n",
      "     4 removed due to exclusion_organ_donor\n",
      " 18691 removed due to exclusion_by_apache\n",
      "\n",
      " 23825 (38.72%) removed so far.\n",
      "  extra   9767 removed due to window time.\n",
      "\n",
      " 27940 (45.41%) - final cohort size.\n",
      "Exported 27940 rows to file.\n"
     ]
    }
   ],
   "source": [
    "print('=== MIMIC ===')\n",
    "\n",
    "query = mimic_schema + \"\"\"\n",
    "select co.*, tm.windowtime_hours\n",
    "from tr_cohort co\n",
    "left join tr_time_day1 tm\n",
    "on co.icustay_id = tm.icustay_id\"\"\"\n",
    "co_mimic = pd.read_sql_query(query, con_mimic)\n",
    "co_mimic.set_index('icustay_id', inplace=True)\n",
    "co_mimic = utils.drop_patients(co_mimic)\n",
    "\n",
    "query = mimic_schema + \"\"\"\n",
    "select co.icustay_id\n",
    "  , a.apsiii\n",
    "from tr_cohort co\n",
    "left join apsiii a\n",
    "  on co.icustay_id = a.icustay_id\n",
    "order by 1, 2\n",
    "\"\"\"\n",
    "df_mimic = pd.read_sql_query(query, con_mimic)\n",
    "df_mimic.set_index('icustay_id', inplace=True)\n",
    "\n",
    "# get static data\n",
    "query = mimic_schema + \"\"\"select * from tr_static_data\"\"\"\n",
    "df_mimic_static = pd.read_sql_query(query, con_mimic)\n",
    "df_mimic_static.set_index('icustay_id', inplace=True)\n",
    "\n",
    "# add in outcomes/static vars to the design matrix\n",
    "vars_static = ['death', 'ventdays',\n",
    "               'is_female', 'age',\n",
    "               'race_black', 'race_hispanic', 'race_asian', 'race_other',\n",
    "               'electivesurgery']\n",
    "X_mimic = df_mimic.merge(df_mimic_static[vars_static], how='inner',\n",
    "                       left_index=True, right_index=True)\n",
    "\n",
    "# add in hospitalid/outcomes to start of dataframe\n",
    "vars_outcome = ['hospitalid', 'hosp_los']\n",
    "X_mimic = co_mimic[vars_outcome].merge(X_mimic, how='inner',\n",
    "              left_index=True, right_index=True)\n",
    "\n",
    "# rearrange certain columns to beginning of dataframe\n",
    "# this is only for aesthetics - nice to have non-inputs at start of df\n",
    "vars_outcome = ['hospitalid', 'death', 'hosp_los', 'ventdays']\n",
    "X_mimic = X_mimic[ vars_outcome + [c for c in X_mimic.columns if c not in vars_outcome] ]\n",
    "X_mimic.head()\n",
    "\n",
    "\n",
    "# write to file\n",
    "X_mimic.to_csv('X_mimic_apsiii.csv.gz', compression='gzip')\n",
    "print('Exported {} rows to file.'.format(X_mimic.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close DB connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mimic.close()\n",
    "con_eicu.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icu-model-transfer",
   "language": "python",
   "name": "icu-model-transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
