{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alistairewj/.virtualenvs/icu-model-transfer/lib/python3.5/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "# logistic regression is our favourite model ever\n",
    "from sklearn import linear_model\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# local utils\n",
    "import utils\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "# default colours/marker/linestyles for prettier plots\n",
    "col = [[0.9047, 0.1918, 0.1988],\n",
    "    [0.2941, 0.5447, 0.7494],\n",
    "    [0.3718, 0.7176, 0.3612],\n",
    "    [1.0000, 0.5482, 0.1000],\n",
    "    [0.4550, 0.4946, 0.4722],\n",
    "    [0.6859, 0.4035, 0.2412],\n",
    "    [0.9718, 0.5553, 0.7741],\n",
    "    [0.5313, 0.3359, 0.6523]];\n",
    "marker = ['v','o','d','^','s','o','+']\n",
    "ls = ['-','-','-','-','-','s','--','--']\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27940 observations. Outcome rate: 9.57%.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('X_mimic_apsiii.csv.gz', sep=',', index_col=0)\n",
    "\n",
    "var_other = ['hospitalid', 'death', 'hosp_los', 'ventdays']\n",
    "df_other = df[var_other]\n",
    "\n",
    "# convenient reference to death column\n",
    "y = df['death'].values\n",
    "\n",
    "# drop everything other than APS III\n",
    "X = df['apsiii'].values.reshape([X.shape[0],1])\n",
    "\n",
    "print('{} observations. Outcome rate: {:2.2f}%.'.format(\n",
    "    X.shape[0], 100.0*np.mean(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== l2 ===============\n",
      "2018-04-20 16:05:14.839097 - Finished fold 1 of 5. AUROC 0.752.\n",
      "2018-04-20 16:05:15.457937 - Finished fold 2 of 5. AUROC 0.767.\n",
      "2018-04-20 16:05:15.896043 - Finished fold 3 of 5. AUROC 0.757.\n",
      "2018-04-20 16:05:16.421651 - Finished fold 4 of 5. AUROC 0.740.\n",
      "2018-04-20 16:05:16.951167 - Finished fold 5 of 5. AUROC 0.749.\n",
      "=============== xgb ===============\n",
      "2018-04-20 16:05:20.163342 - Finished fold 1 of 5. AUROC 0.745.\n",
      "2018-04-20 16:05:23.312978 - Finished fold 2 of 5. AUROC 0.761.\n",
      "2018-04-20 16:05:26.630656 - Finished fold 3 of 5. AUROC 0.751.\n",
      "2018-04-20 16:05:29.770076 - Finished fold 4 of 5. AUROC 0.736.\n",
      "2018-04-20 16:05:32.894601 - Finished fold 5 of 5. AUROC 0.739.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(71017)\n",
    "\n",
    "K = 5\n",
    "idxK = np.random.permutation(X.shape[0])\n",
    "idxK = idxK % K\n",
    "\n",
    "# parameters from grid search\n",
    "models = {'l2': linear_model.LogisticRegressionCV(n_jobs=4),\n",
    "          'xgb': xgb.XGBClassifier(colsample_bytree=0.7, silent=1,\n",
    "                            learning_rate=0.01, n_estimators=1000,\n",
    "                            subsample=0.8, max_depth=9, n_jobs=4)\n",
    "         }\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "smr_val = dict()\n",
    "pred_val = dict()\n",
    "pred_val_merged = dict()\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    smr_val[mdl] = list()\n",
    "    pred_val[mdl] = dict()\n",
    "    pred_val_merged[mdl] = np.zeros(X.shape[0])\n",
    "    \n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = sklearn.base.clone(estimator).fit(X[idxK != k, :], y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl in ('lasso','ridge'):\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "            \n",
    "        pred_val_merged[mdl][idxK==k] = curr_prob\n",
    "        pred_val[mdl][k] = curr_prob\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "        \n",
    "        # also get SMR\n",
    "        smr_val[mdl].append(np.sum(y[idxK == k]) / np.sum(curr_prob))\n",
    "        \n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "        \n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "    \n",
    "tar_val = dict()\n",
    "for k in range(K):\n",
    "    tar_val[k] = y[idxK==k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cross-validation performance to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model-performance-cv-soi.csv', 'w') as fp:\n",
    "    fp.write('{},{},{}\\n'.format('model','auc','smr'))\n",
    "    for mdl in results_val:\n",
    "        fp.write('{}'.format(mdl))\n",
    "        fp.write(',{}'.format(np.mean(results_val[mdl])))\n",
    "        fp.write(',{}'.format(np.mean(smr_val[mdl])))\n",
    "        fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icu-model-transfer",
   "language": "python",
   "name": "icu-model-transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
